{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GD-06] NLP-Bias in Word Embeddings.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [GD-06] Bias in Word Embeddings\n",
        "\"Going Deeper Node 6. Checking Bias in Word Embeddings\" / 2022. 04. 04 (MON) 이형주\n",
        "\n",
        "## Contents\n",
        "---\n",
        "- **1. Environment Setup & EDA**\n",
        "- **2. Modeling**\n",
        "- **3. Project Retrospective**\n",
        "\n",
        "## Rubric 평가기준\n",
        "---\n",
        "\n",
        "|  평가문항  |  상세기준  |\n",
        "|:---------|:---------|\n",
        "|1. 주어진 영화 코퍼스를 바탕으로 워드임베딩 모델을 정상적으로 만들었다.|워드임베딩의 most_similar() 메소드 결과가 의미상 바르게 나왔다.\n",
        "|2. 영화 구분, 장르별로 target, attribute에 대한 대표성있는 단어 셋을 생성하였다.|타당한 방법론을 통해 중복이 잘 제거되고 개념축을 의미적으로 잘 대표하는 단어 셋이 만들어졌다.\n",
        "|3. WEAT score 계산 및 시각화를 정상적으로 진행하였다.|전체 영화 장르별로 예술/일반 영화에 대한 편향성 WEAT score가 상식에 부합하는 수치로 얻어졌으며 이를 잘 시각화하였다."
      ],
      "metadata": {
        "id": "lxzYg25dNHvC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ABxC0R1M5Uo",
        "outputId": "40045956-1353-4cfa-e77c-543d7ad51071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr  4 14:39:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Colab Pro GPU 정보\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Pro Ram 정보\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfLkBRMdPWIN",
        "outputId": "b3c4463b-1d7d-4270-9d0f-44110b109c5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup & EDA"
      ],
      "metadata": {
        "id": "iUgE5XHrZSyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "import konlpy\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "import gensim \n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import seaborn\n",
        "\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "B_wTtw5XBIWl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1. 형태소 분석기를 이용하여 품사가 명사인 경우 해당 단어를 추출하기\n",
        "# STEP 2. 추출된 결과로 embedding model 만들기\n",
        "# STEP 3. target, attribute 단어 셋 만들기\n",
        "# STEP 4. WEAT score 계산과 시각화"
      ],
      "metadata": {
        "id": "Y7V7Ku8DDL5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}