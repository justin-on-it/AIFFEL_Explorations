{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[GD-04] NLP-Bias in Word Embeddings.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [GD-08] Seq2seq\n",
        "\"Going Deeper Node 8. Making translator using Seq2seq\" / 2022. 04. 07 (Thu) 이형주\n",
        "\n",
        "## Contents\n",
        "---\n",
        "- **1. Environment Setup**\n",
        "- **2. Modeling**\n",
        "- **3. Project Retrospective**\n",
        "\n",
        "## Rubric 평가기준\n",
        "---\n",
        "\n",
        "|  평가문항  |  상세기준  |\n",
        "|:---------|:---------|\n",
        "|1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 한국어 포함하여 잘 이루어졌다.|구두점, 대소문자, 띄어쓰기, 한글 형태소분석 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.\n",
        "|2. Attentional Seq2seq 모델이 정상적으로 구동된다.|seq2seq 모델 훈련 과정에서 training loss가 안정적으로 떨어지면서 학습이 진행됨이 확인되었다.\n",
        "|3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|테스트용 디코더 모델이 정상적으로 만들어져서, 정답과 어느 정도 유사한 영어 번역이 진행됨을 확인하였다."
      ],
      "metadata": {
        "id": "PmEWbZjkUvvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Pro GPU 정보\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "id": "aU54PJPSU2s1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "640ec65e-a2c9-4cfb-8e41-0c88a07ceffb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Apr  7 14:31:47 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab Pro Ram 정보\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "id": "OOHuxWbmU3Ic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba00193a-d54c-4eff-dc33-2f3a44231387"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Environment Setup"
      ],
      "metadata": {
        "id": "ZGTEvyHcU7sz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import random\n",
        "import matplotlib.ticker as ticker\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "sF1aMV7UVdpV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "# 데이터가 존재하는 웹 주소\n",
        "DOWNLOAD_ROOT = \"https://github.com/jungyeul/korean-parallel-corpora/blob/master/korean-english-news-v1/\"\n",
        "# 다운받을 정상/스팸 파일 명\n",
        "DEV_URL = DOWNLOAD_ROOT + \"korean-english-park.dev.tar.gz\"\n",
        "TEST_URL = DOWNLOAD_ROOT + \"korean-english-park.test.tar.gz\"\n",
        "TRAIN_URL = DOWNLOAD_ROOT + \"korean-english-park.train.tar.gz\"\n",
        "# 파일을 저장할 로컬 디렉토리 경로\n",
        "DATA_PATH = os.path.join(\"datasets\")"
      ],
      "metadata": {
        "id": "qRwkPrB3cDUd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data_path(dev_path=DEV_URL, test_path=TEST_URL, train_path=TRAIN_URL):\n",
        "    if not os.path.isdir(DATA_PATH): # 디렉토리 존재 유무 확인\n",
        "        os.makedirs(DATA_PATH)\n",
        "    for filename, url in ((\"korean-english-park.dev.tar.gz\", DEV_URL), \n",
        "                          (\"korean-english-park.test.tar.gz\", TEST_URL), \n",
        "                          \"korean-english-park.train.tar.gz\", TRAIN_URL):\n",
        "        path = os.path.join(DATA_PATH, filename)\n",
        "        if not os.path.isfile(path): # 파일 존재 유무 확인\n",
        "            # 파일이 없으면 path로 전달한 경로로 url에 해당하는 파일을 저장\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "            \n",
        "        # 압축해제\n",
        "        tar = tarfile.open(path)\n",
        "        tar.extractall(path=DATA_PATH)\n",
        "        tar.close()"
      ],
      "metadata": {
        "id": "oNNBZ7SEZb4u"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Modeling"
      ],
      "metadata": {
        "id": "-4macfGuU9YP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Project Retrospective"
      ],
      "metadata": {
        "id": "adWzsJFyU_UY"
      }
    }
  ]
}